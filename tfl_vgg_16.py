# -*- coding: utf-8 -*-
"""TFL VGG_16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aE7pEe-U95JbF3PXTznvvDcqXnx9f_xF
"""

# importing the necessary libraries
import numpy as np
import os
from skimage.io import imread
from skimage.transform import resize
from skimage.color import gray2rgb
import pandas as pd
import tensorflow 
import keras
from keras.models import Sequential
from keras.regularizers import l2
from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Dense, Activation, Dropout, Flatten
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score
from keras.layers.normalization import BatchNormalization
from tensorflow.keras.optimizers import SGD
from keras import backend as K
from keras.layers import Input, Lambda, Dense, Flatten
from keras.models import Model
from keras.applications.vgg16 import VGG16
import matplotlib.pyplot as plt
import itertools

from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization
from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout

# re-size all the images to this
IMAGE_SIZE = [224, 224,3]
image_input = Input(shape=(224, 224, 3))
vgg16 = VGG16(include_top=False, weights="imagenet",input_tensor=None,input_shape= IMAGE_SIZE, classes=2)
output = vgg16.layers[-1].output
output = keras.layers.Flatten()(output)
vgg16model=Model(vgg16.input, output)
# don't train existing weights
for layer in vgg16model.layers:
  layer.trainable = False
vgg16model.summary()

num_classes=2
model=Sequential()
model.add(vgg16model)
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(512, activation='relu', input_dim=IMAGE_SIZE,kernel_regularizer=l2(0.000001)))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

# changing the location to the project directory
os.chdir('/content/drive/My Drive/Test 8')
dim=(224,224)
imageShape = (dim[0],dim[1],3)
numClasses = 2
batchSize = 20
epochs = 50
folderWithPics='twitter'
dirs=os.listdir('./'+folderWithPics)
#print(dirs)

# Reading the sentiment labels from the groundTruthLabel.txt file for all the images
clsLabels=pd.read_csv('./'+folderWithPics+'/groundTruthLabel.txt',delimiter='\t')
clsLabels.index=clsLabels.index+1
#print (clsLabels)
#print(clsLabels.index)

#Getting the training and testing images (partition 1) path from twitter folder
subDirPath=[('./'+folderWithPics+'/'+di) for di in dirs if('txt' not in di)]
allImagesTestPath=[(si+'/'+ii) for si in [subDirPath[-1]] for ii in os.listdir(si) if('jpg' in ii)]
print(allImagesTestPath)
allImagesTrainPath=[(si+'/'+ii) for si in subDirPath[:-1] for ii in os.listdir(si) if('jpg' in ii)]  
print(allImagesTrainPath)

def formImageSet(allImagesFoldrPath,dim,clsLabels):
    x_imageSet=np.empty((len(allImagesFoldrPath),dim[0],dim[1],3))
    y_Set=np.empty((len(allImagesFoldrPath),1))
    for im in range(len(allImagesFoldrPath)):
        readImage=imread(allImagesFoldrPath[im])
        #print(allImagesFoldrPath[im].split('/')[-1].split('.')[0])
        
        imNum=int(allImagesFoldrPath[im].split('/')[-1].split('.')[0])
        actualClass=clsLabels.loc[imNum][1]
        
        if (actualClass=='positive'):
            y_Set[im]=1
        else:
            y_Set[im]=0
            
        if (len(readImage.shape)>=3):
            if readImage.shape[2]>3:
                readImage=readImage[:,:,:3]            
        else:
            print(im,readImage.shape)
            readImage=gray2rgb(readImage)            
        readImage=resize(readImage,dim)
        x_imageSet[im]=readImage
    return x_imageSet,y_Set

def prepareDataSet():
    xTrainImSet,yTrainSet=formImageSet(allImagesTrainPath,dim,clsLabels)
    xTestImSet,yTestSet=formImageSet(allImagesTestPath,dim,clsLabels)
    
    xTrainImSet= xTrainImSet.astype('float32')
    xTestImSet= xTestImSet.astype('float32')
    xTrainImSet /= 255.0
    xTestImSet /= 255.0
    
# Categorical representation by converting the class vectors to matrices as binary
    yTrainSet= keras.utils.to_categorical(yTrainSet, numClasses)
    yTestSet= keras.utils.to_categorical(yTestSet, numClasses)
    
    print('Train Dataset size: ', xTrainImSet.shape[0])
    print('Test Dataset size: ', yTestSet.shape[0])
    
    return (xTrainImSet,yTrainSet), (xTestImSet,yTestSet)

# prepare the data set
print('Prepare data set...')
(xTrainImSet,yTrainSet), (xTestImSet,yTestSet) = prepareDataSet()

print('Set the optimizer and compile the model')

optimizer = tensorflow.keras.optimizers.Adam()
model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

#Train the model
print('Train the model')
res= model.fit(xTrainImSet, yTrainSet,batch_size=batchSize,validation_data=(xTestImSet, yTestSet),epochs=epochs,shuffle=True)

print('Testing the model')
score = model.evaluate(xTestImSet, yTestSet)
print('Test accuracy: ', score[1],'Test loss: ', score[0])

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

y_pred= model.predict(xTestImSet)
rounded_test= np.argmax(y_pred, axis=1)
#print(xTestImSet[1])

rounded_labels=np.argmax(yTestSet, axis=1)
print(rounded_labels[1])

cm= confusion_matrix(rounded_labels,rounded_test)
print(cm)
plot_confusion_matrix(cm, classes=['Positive', 'Negative'])

#Classification report 
rounded_labels=np.argmax(yTestSet, axis=1)
class_report=classification_report(rounded_labels,rounded_test,target_names=['Positive','Negative'])

print(class_report)

# loss
plt.plot(res.history['loss'], label='train loss')
plt.plot(res.history['val_loss'], label='test loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend()
plt.show()

plt.plot(res.history['accuracy'])
plt.plot(res.history['val_accuracy'])

plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

plt.plot(res.history['loss'])
plt.plot(res.history['val_loss'])

plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train','test'], loc='upper left')
plt.show()

from tensorflow.python.client import device_lib
device_lib.list_local_devices()